<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to collecting web data with R</title>
    <meta charset="utf-8" />
    <meta name="author" content=" Ivo Bantel      University of Zurich   Centre for Comparative &amp; International Studies                   " />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Introduction to collecting web data with R
### <big> Ivo Bantel <br> <br> <small> University of Zurich <br> Centre for Comparative &amp; International Studies <br> <br> <a href='https://www.ipz.uzh.ch/en/institut/mitarbeitende/staff/ibantel.html'> <i class='fas fa-home' style='font-size:.9em;' ></i> </a>  <a href='mailto:bantel@ipz.uzh.ch'> <i class='fas fa-envelope' style='font-size: .9em;'></i> </a>  <a href='https://twitter.com/ivobantel'> <i class='fab fa-twitter' style='font-size: .9em;'></i> </a> <br> <br>
### March 5, 2021 (4:30-5:45)

---


layout: true

&lt;div class="my-footer"&gt;
  &lt;span style="text-align:center"&gt;
    &lt;span&gt;
      &lt;img src="https://upload.wikimedia.org/wikipedia/commons/c/ce/Cc-by-nc-sa_euro_icon.svg" height=14 style="vertical-align: middle"/&gt;
    &lt;/span&gt;
      &lt;a href = "https://github.com/ibantel/2021-03-05_CEU_Webscraping-with-R"&gt;
        &lt;span style="padding-left:82px"&gt;
          &lt;font color="#7E7E7E"&gt;Ivo Bantel (UZH / CIS)&lt;/font&gt;
        &lt;/span&gt;
        &lt;font color="#7E7E7E"&gt;Collecting web data with R | March 5, 2021&lt;/font&gt;
      &lt;/a&gt;
&lt;/div&gt; 

&lt;style&gt;
p.large {
    font-size: 15px;
    background-color: tomato;
}
&lt;/style&gt;

---

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
## While you wait...

... please ensure you installed all necessary packages

&lt;br&gt;
.pull-right95[

```r
install.packages(c("rvest", "tidyverse", "knitr", "rmarkdown", "xml2"))
```
]

???

- Please make sure you have installed all packages
- if you run into problems, please try restarting RStudio and trying again. 
- If you still have problems, we'll have to figure that out prior to the first exercise


- also, please turn on cameras :) 


---




.pull-left6[

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;


## Goal


&gt;### Introduce the fundamentals of web scraping, with hands-on experience!

]

.pull-right4[

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
&lt;p align="center"&gt;&lt;img src="./img/target.png" height="350"&gt;&lt;/p&gt;

]

???

- In this short workshop, I'm trying to 
- give you a first introduction to what web is,
- how you can do it, and 
- give you some hands-on experience

---

&lt;br&gt;
## Schedule 

.pull-left[&lt;br&lt;br&gt;&lt;br&gt;&lt;img src="./img/agenda.jpg" height="300"&gt; &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;]

&lt;ul&gt;
    &lt;li style="font-size: 30px"&gt;Background scraping&lt;/li&gt;&lt;br&gt;
    &lt;ul class="level"&gt;
        &lt;li style="font-size: 22px"&gt;why you should (not) scrape&lt;/li&gt;&lt;br&gt;
        &lt;li style="font-size: 22px"&gt;varieties of scraping&lt;/li&gt;&lt;br&gt;
        &lt;li style="font-size: 22px"&gt;HTML&lt;/li&gt;&lt;br&gt;&lt;br&gt;
    &lt;/ul&gt;
    &lt;li style="font-size: 30px"&gt;Exercises web scraping&lt;/li&gt;&lt;br&gt;
&lt;/ul&gt; 

???

- In the next hour or so,
- I'll first introduce scraping and what to consider when doing it
- then I'll talk on different varieties of scraping and
- the basics of HTML and CSS selectors
- We'll then take a little break and in the second part, we'll practise web scraping,
    - we'll extract content from web pages using CSS selector and
    - scrape tables
- if we have time in the end, I'll also say a few words about scaling up and scraping several pages (e.g. with loops and functions)

- for these exercises, you will be in smaller breakout rooms to help each other where you can


---

&lt;br&gt;
## About me: Ivo Bantel
.pull-left65[


&lt;br&gt;&lt;br&gt;
&lt;ul&gt;
  &lt;li class="m1" style="font-size: 25px"&gt;PhD student (UZH, Digital Democracy Lab)&lt;/li&gt;&lt;br&gt;&lt;br&gt;
  &lt;li class="m2" style="font-size: 25px"&gt;_research interests_:&lt;/li&gt;
    &amp;#8239; &amp;#8239; &amp;#8239; &amp;#8239; polarization, extreme right politics, political violence,&lt;br&gt;
    &amp;#8239; &amp;#8239; &amp;#8239; &amp;#8239; web scraping, quantitative text analysis&lt;br&gt;&lt;br&gt;&lt;br&gt;
  &lt;!--- &lt;li class="m2"&gt;_teaching_: webscraping, qualitative methods, substantive courses&lt;/li&gt;&lt;br&gt;---&gt;
  &lt;li class="m2" style="font-size: 25px"&gt;_Contact:_&lt;/li&gt;&lt;br&gt;
  &amp;#8239; &amp;#8239; &amp;#8239; &amp;#8239;
  &lt;i class='fas fa-envelope' style='font-size:.9em;' &gt;&lt;/i&gt; &amp;#8239; &amp;#8239; &amp;#8239; [bantel@ipz.uzh.ch](mailto:bantel@ipz.uzh.ch)
  &lt;br&gt; &amp;#8239; &amp;#8239; &amp;#8239; &amp;#8239;
  &lt;i class='fab fa-twitter' style='font-size: .9em;'&gt;&lt;/i&gt; &amp;#8239; &amp;#8239; &amp;#8239; [@ivobantel](https://twitter.com/ivobantel) 
  &lt;br&gt;
&lt;ul&gt;
]

.pull-right25[
&lt;a href='https://www.ipz.uzh.ch/en'&gt;&lt;img src="./img/uzh.png" alt="UZH logo" height='200'&gt; &lt;br&gt;
&lt;a href='https://www.ipz.uzh.ch/en'&gt;&lt;img src="./img/digdemlab.png" alt="DigDemLab logo" height='100'&gt;

&lt;!--- https://fontmeme.com/name-tags/ ---&gt;

]

???

- To get started I want to introduce myself and then get to know some things about you
- I will introduce myself quickly. 
- I'm doing my PhD at the University of Zurich, and I'm also part of the Digital Democracy Lab, which is a research hub focusing on the implications of digital technology for politics and democracy using computational social science methods
- we also provide a research infrastructure that enables efficient, scalable, and replicable data collection and analysis for collaborators, so check that out if you're interested 

- my substantive research areas are polarization, extreme right politics, and terrorism (in that order) ;)
- and methodologically, I'm interested in computational methods of data collection and analysis, like web scraping and quantitative text analysis

---

&lt;br&gt;
## Getting to know you

???
- Due to the limited time, we won't be able to go around for everyone to introduce themselves unfortunately. So I will have to get to know you quantitatively - sorry for that! If you want to stick around for a drink later on, I'd be happy to chat for a bit.
But for now, I have some questions. Please use *Yes*, *No* etc. in Zoom.
- To get to know you, I'll ask a few questions and ask you to use the reactions buttons
- First question: "I have found the "open mouth" button".

--

&lt;br&gt;

- How much experience do you have with R? &lt;br&gt; 
  &amp;nbsp; &lt;img src="./img/open-mouth.png" alt="open mouth" height="20"/&gt; &amp;nbsp; None &amp;nbsp;  &amp;nbsp;  &amp;nbsp;
  &amp;nbsp; &lt;img src="./img/no.png" alt="no" height="20"/&gt; &amp;nbsp; Some  &amp;nbsp;  &amp;nbsp;  &amp;nbsp;
  &amp;nbsp; &lt;img src="./img/yes.png" alt="yes" height="20"/&gt; &amp;nbsp; I can write functions &amp;nbsp;  &amp;nbsp;  &amp;nbsp;
  &amp;nbsp; &lt;img src="./img/heart.png" alt="heart" height="20"/&gt; &amp;nbsp; I'm a pro


--

&lt;br&gt;

- Have you used `RMarkdown` notebooks before? &lt;br&gt; 
  &amp;nbsp; &lt;img src="./img/open-mouth.png" alt="open mouth" height="20"/&gt; &amp;nbsp; Don't know what that is &amp;nbsp;  &amp;nbsp;  &amp;nbsp;
  &amp;nbsp; &lt;img src="./img/no.png" alt="no" height="20"/&gt; &amp;nbsp; I've opened one  &amp;nbsp;  &amp;nbsp;  &amp;nbsp;
  &amp;nbsp; &lt;img src="./img/yes.png" alt="yes" height="20"/&gt; &amp;nbsp; I've written some &amp;nbsp;  &amp;nbsp;  &amp;nbsp;
  &amp;nbsp; &lt;img src="./img/heart.png" alt="heart" height="20"/&gt; &amp;nbsp; All the time

--

&lt;br&gt;

- Have you ever webscraped? &lt;br&gt;
  &amp;nbsp; &lt;img src="./img/open-mouth.png" alt="open mouth" height="20"/&gt; &amp;nbsp; What _is_ that? &amp;nbsp; &amp;nbsp;
  &amp;nbsp; &lt;img src="./img/no.png" alt="no" height="20"/&gt;                 &amp;nbsp; Never           &amp;nbsp; &amp;nbsp;
  &amp;nbsp; &lt;img src="./img/yes.png" alt="yes" height="20"/&gt;               &amp;nbsp; Once            &amp;nbsp; &amp;nbsp;
  &amp;nbsp; &lt;img src="./img/heart.png" alt="heart" height="20"/&gt;           &amp;nbsp; I could teach it

--
 

&lt;br&gt;

- How comfortable are you with HTML? &lt;br&gt;
  &amp;nbsp; &lt;img src="./img/open-mouth.png" alt="open mouth" height="20"/&gt; &amp;nbsp; HTwhat? &amp;nbsp; &amp;nbsp; &amp;nbsp;
  &amp;nbsp; &lt;img src="./img/no.png" alt="no" height="20"/&gt;                 &amp;nbsp; Heard of it    &amp;nbsp; &amp;nbsp;
  &amp;nbsp; &lt;img src="./img/yes.png" alt="yes" height="20"/&gt;               &amp;nbsp; I know basics  &amp;nbsp; &amp;nbsp;
  &amp;nbsp; &lt;img src="./img/heart.png" alt="heart" height="20"/&gt;           &amp;nbsp; I'm fluent



&lt;br&gt;
 

&lt;!--- - Is there a specific webpage you want to scrape? (Use chat) ---&gt;

---

class: inverse, center, middle
## Background scraping


???

- let's get started with the content then

- I will first give some background for everyone to understand how we can leverage `R` to automatically collect data from the web

- afterwards, we'll go through a few exercises

---

&lt;br&gt;
## Scraping &amp;mdash; and why you...
&lt;br&gt;

???

- I'll now quickly talk about the advantages of scraping -- and its dangers.
- I won't be able to discuss this in detail but just want to make you aware of some considerations you should keep in mind

- I assume that you all have some idea -- maybe too optimistic -- about why web scraping helps
- but why should we scrape?

--

.pull-left45[

### &amp;nbsp; &amp;nbsp; &amp;nbsp; ... should do it
&lt;br&gt; 

**Data availability**: &lt;br&gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; increasing amount of...
- public data online ("open government")&lt;br&gt;&lt;br&gt;
- politics happens online&lt;br&gt;&lt;br&gt;
- people use the internet - and share everything online&lt;br&gt;&lt;br&gt;
- data online makes real world phenomena more visible online 
] 


???

- In short, there are lots of data out there that is online that we can access (only or more easily with web scraping)
- This includes data from government sources, politics that happens online -- political actors using online platforms to e.g. perform political actions; not just since the pandemic; but this also includes individuals sharing a lot online
- in sum, all this data online makes real world phenomena more visible online

- okay, now that we know what the benefits are, why should we **not** scrape?
- as you might have thought from the list I just went through, there are also some drawbacks and limiting considerations
- We can only touch upon the legal and ethical questions here
- but i will highlight some points you need to be aware of


--

.pull-right45[
### &amp;nbsp; &amp;nbsp; &amp;nbsp; ...should _not_ do it

&lt;br&gt; 

**Legal, ethical, and logistical barriers**

- criminal code, copyright laws etc. &lt;br&gt; &amp;rarr; check `robots.txt`, use `polite` package&lt;br&gt;&lt;br&gt;
- terms of service / measures to prevent scraping&lt;br&gt;&lt;br&gt; &lt;!--- (API restrictions, 'distributed Turing test') ---&gt;
- ethical regulations and considerations &lt;!----(privacy, GDPR, informed consent)----&gt;

] 

???

- the first thing to keep in mind is that you could actually break law when scraping; to prevent that, every page provides a file called robots.txt that tells you what you're not supposed to do on this site
- similarly, some sites have measures in place to prevent you from scraping because it's against their terms of service
- finally, ethical considerations: if you're scraping e.g. personal data, you need to be aware of privacy question and informed consent of your subjects!!! please take this seriously! web scraping is a powerful tool, use it wisely!


---

&lt;br&gt;
## Scraping: what is out there?

--

.pull-left45[

&lt;br&gt;&lt;b&gt;&lt;font size=6 color = "000000"&gt;1. Scraping static pages&lt;/font&gt;&lt;/b&gt;&lt;/li&gt;

]

.pull-right45[

  &lt;a href = "https://www.theguardian.com/international"&gt;
    &lt;img src="./img/theguardian.png" height=400 style="vertical-align: middle"/&gt;
  &lt;/a&gt;
  &lt;font size=1&gt;Screenshot "The Guardian"&lt;/font&gt;

]

???

- Scraping: extracting data from the web
 - includes anything from university webpage to social media
 - lots of different techniques

- types of scraping
 - structured vs. unstructured data
 - gathering as diverse information as possible from different pages vs. very specific scrapers
 - one-off scraping vs. regular data collection


1. Static pages (that is what we'll cover today)
- extracting text, links and tables from many standard webpages
    - page written in HTML / XML
    - page has a static URL through which you can reach it

Procedure
- 'parsing' page in R
- extracting relevant parts
- cleaning into usable format (e.g. data frame, raw text, ...)

---

&lt;br&gt;
## Scraping: what is out there?


.pull-left45[

&lt;br&gt;&lt;b&gt;&lt;font size=6 color = "A0A0A0"&gt;1. Scraping static pages&lt;/font&gt;&lt;/b&gt;&lt;/li&gt;
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;font size=6 color = "000000"&gt;2. APIs &lt;font size=4&gt;(application programming interface)&lt;/font&gt;&lt;/font&gt;&lt;/li&gt;

]

.pull-right45[

  &lt;a href = "https://www.data.gov/developers/apis"&gt;
    &lt;img src="./img/datagovapi.png" height=400 style="vertical-align: middle"/&gt;
  &lt;/a&gt;
  &lt;font size=1&gt;Screenshot "DATA.GOV"&lt;/font&gt;

]

???

2. APIs

- companies and governments often provide **application programming interfaces** for their data
    - increasing accessibility, reliability
    - used for scraping and interaction with apps

- Differences to static pages
  - structured data in specific notation (often JSON)
  - access through sending requests, e.g. with `httr` package
  - in many cases: R packages for access to API, e.g. `gender`, `rtweet`, `WikipediR`, `tuber`, ...

- pro: 1) legal and robust to changes in webpage structure; 2) highly standardized
- con: 1) availability: not every page has API; 2) speed: rate limits / restrictions to amount of data; 3) may be terminated: ['post API age'](https://www.tandfonline.com/doi/full/10.1080/10584609.2018.1477506) 


---

&lt;br&gt;
## Scraping: what is out there?


.pull-left45[

&lt;br&gt;&lt;b&gt;&lt;font size=6 color = "A0A0A0"&gt;1. Scraping static pages&lt;/font&gt;&lt;/b&gt;&lt;/li&gt;
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;font size=6 color = "A0A0A0"&gt;2. APIs &lt;font size=4&gt;(application programming interface)&lt;/font&gt;&lt;/font&gt;&lt;/li&gt;
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;font size=6 color = "000000"&gt;3. Dynamic pages&lt;/font&gt;&lt;/li&gt;

]

.pull-right45[

  &lt;br&gt;&lt;br&gt;&lt;br&gt;
    &lt;img src="./img/netflix.png" width=400 style="vertical-align: middle"/&gt;
  &lt;br&gt;
  &lt;font size=1&gt;Screenshot "Netflix.com"&lt;/font&gt;

]



???

3. dynamic pages
- for scraping pages that change while you are on them without changing their URL
    - e.g. Netflix, Buzzfeed, (many) search functions, pages without permanent URL

- Differences to static pages
  - simulates web browsing rather than parsing static page
  - scraping through commands to browser

- pro
    - get around many restrictions to scraping
    - possibility to automate browsing
- con
    - difficult to set up
    - less robust than static scraping
    - legal concerns

---

&lt;br&gt;
## Scraping: what is out there?


.pull-left45[

&lt;br&gt;&lt;b&gt;&lt;font size=6 color = "A0A0A0"&gt;1. Scraping static pages&lt;/font&gt;&lt;/b&gt;
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;font size=6 color = "A0A0A0"&gt;2. APIs &lt;font size=4&gt;(application programming interface)&lt;/font&gt;&lt;/font&gt;&lt;/li&gt;
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;font size=6 color = "A0A0A0"&gt;3. Dynamic pages&lt;/font&gt;
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;font size=6 color = "000000"&gt;4. Web crawlers / spiders&lt;/font&gt;

]

.pull-right45[

  &lt;br&gt;
    &lt;img src="./img/crawler.png" width=400 style="vertical-align: middle"/&gt;
  &lt;br&gt;
  &lt;font size=0.1&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Created by Symbolon from the Noun Project&lt;/font&gt;

]

???

4. web crawling / spiders

- parsing of massive amounts of data
    - e.g. price data, building a search engine, ...
- reading of pages as usual but parsing e.g. through `boilerpipeR`

- Differences to static pages
  - no selection of specific parts but use of *heuristics* on HTML code
      - &amp;rarr; less exact but less labor-intensive extraction of content
  - pro
    - masses of data
  - con
    - masses of data (that are unclear)

- **are there any questions?**

---

class: inverse, center, middle 
## HTML


???

before we can dive into the exercises, we need to get some understandingof HTML

- refers to **H**yper **T**ext **M**arkup **L**anguage
  - *markup*: additional description of formatting beyond the content of the text
  
  - let's consider an example

---

&lt;br&gt;
## HTML 101: example

&lt;br&gt; 


.pull-left45[

### turning this... 
  &lt;br&gt;
    &lt;img src="./img/quotes2scrape_code.png" style="vertical-align: middle"/&gt;
  &lt;br&gt;
  &lt;font size=0.1&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Screenshot sourcecode [quotes.toscrape.com](http://quotes.toscrape.com/).&lt;/font&gt;
  
]


--

.pull-right45[

### ...into this
  &lt;br&gt;&lt;br&gt;&lt;br&gt;
    &lt;img src="./img/quotes2scrape.png" style="vertical-align: middle"/&gt;
  &lt;br&gt;
  &lt;font size=0.1&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Screenshot [quotes.toscrape.com](http://quotes.toscrape.com/).&lt;/font&gt;

]

???
HTML turns this code ...

 ... into this (more or less) beautiful home page

---

&lt;br&gt;
## HTML 101: components

???

- let's take a step back and look at some HTML

--

.pull-right45[&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;img src="./img/boldtext.jpg" width="400"&gt;]


???

- Let's look at some HTML text.
- if we type this into a code editor and specify that this is a HTML document, the syntax highlighting will look similar to this
- we can see here that there are two components: white text and colored text

--

&lt;br&gt;

.pull-left55[ &lt;br&gt;

1. **HTML elements** (e.g. text, images)&lt;br&gt;&lt;br&gt;

2. **HTML tags**&lt;br&gt;&lt;br&gt;

  - specify elements' _character_ or _behaviour_&lt;br&gt;&lt;br&gt;

  - usually start &amp; end tag &lt;br&gt; &amp;nbsp; (exceptions: images, line breaks, ...)&lt;br&gt;&lt;br&gt;

  - surround the element they modify
&lt;br&gt;

]


???

- these are the two components of HTML: html elements and html tags

- we want to scrape the text (we could also scrape embedded images, e.g. for visual analysis etc.)
- but to _get_ the text, we need to access the parts we cant using the tags

--

&lt;br&gt;

.pull-right45[&lt;br&gt;
Example: &lt;br&gt;&lt;br&gt;

&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; `&lt;tagname&gt;` &lt;br&gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;  &amp;nbsp;  &amp;nbsp; `Some content here...` &lt;br&gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; `&lt;/tagname&gt; `]

???

- To make a generic example, this would be something like this


---

&lt;br&gt;
## HTML tags: basics

.pull-right85[
&lt;br&gt;&lt;br&gt;
``` 
&lt;html&gt; 
    &lt;head&gt; 
        &lt;title&gt;Title of your web page&lt;/title&gt; 
    &lt;/head&gt; 
    &lt;body&gt; 
      &lt;h1&gt;Heading&lt;/h1&gt;
      &lt;p&gt;HTML web page content&lt;/p&gt;
    &lt;/body&gt; 
&lt;/html&gt; 
```
]

???
- let's look at an example -- hich tags can you see here?

- we are mostly interested in what is inside the **body**, that is, the content of a webpage
- **head** gives meta information, often used by search engines; we tend to ignore it
- as we see in the `&lt;h1&gt;` part, tags can be **nested**

---

&lt;br&gt;
## HTML tags: headings &amp; paragraphs

&lt;br&gt;&lt;br&gt;

&lt;ol&gt;
&lt;li&gt;Headings (defined by numbered h tags):&lt;/li&gt;

`&lt;h1&gt;my heading&lt;/h1&gt;` &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;font size=12&gt;my heading&lt;/font&gt;

`&lt;h2&gt;a smaller heading&lt;/h2&gt;` &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;font size=6&gt;a smaller heading&lt;/font&gt;

--

&lt;br&gt;&lt;br&gt;
&lt;li&gt;Paragraphs are defined by "div" or "p" tags&lt;/li&gt;

`&lt;p&gt;this is a paragraph.&lt;/p&gt;&lt;div&gt;and this is the next.&lt;/div&gt;`
&lt;p&gt;this is a paragraph.&lt;/p&gt;&lt;div&gt;and this is the next.&lt;/div&gt;


---

&lt;br&gt;
## HTML tags: attributes

.pull-right75[`&lt;tagname attribute="x"&gt; Some text here &lt;/tagname&gt;`]

&lt;br&gt;

--
&lt;br&gt;
**Links and attributes**


.pull-left45[
`&lt;a href="http://theguardian.co.uk"&gt; Link&lt;/a&gt; to theguardian.co.uk` 

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="http://theguardian.co.uk"&gt;Link&lt;/a&gt; to theguardian.co.uk
]

.pull-right55[

  
  `&lt;img src="cat.jpg" href="wikipedia.org/wiki/Cat"`
  &lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;`alt="My cat" width="400"&gt;`
  
  
  
  .pull-right85[&lt;br&gt;&lt;img src="./img/cat2.jpg" href="wikipedia.org/wiki/Cat" alt="Picture of my cat" width="400" align="left"&gt;]
  

]

???
- All HTML elements can have attributes
- Attributes provide additional information about an element
    - they are included inside the starting tag
    - they usually come in name and value pairs
- examples are the source of an image, its width, the target of a hyperlink, etc.
    
Tags can have attributes -- the most common case of attributes are **links**
- text or images turned into a link by surrounding `&lt;a&gt;` tag (*anchor*)
- link address specified as href attribute (*hyperreference*)

- other examples of attributes
  - alt: descriptions, e.g. for images
      - for users with visual impairments, when image is missing
  - src: source file ` &lt;img src="no_smiley.jpg" alt="Image that does not exist."&gt; `
  - style: text styling (e.g. color ` &lt;p style="color:red"&gt;This is a paragraph.&lt;/p&gt; `)

- how many attributes do we have for each? which ones?

---

&lt;br&gt;
## HTML tags: Classes


&lt;br&gt;

### General example

.pull-left75[&lt;br&gt;

`&lt;div class="container"&gt;This is the text&lt;/div&gt; `

]

.pull-right25[&lt;br&gt;&lt;div class="container"&gt; This is the text&lt;/div&gt;

]

&lt;br&gt;

???

- **Classes** are another special case of attributes that is used for formatting 
    - for our purposes, classes styles that are specified before
    - classes are used within tags
    
- what is the name of the class here?

--

### Styling with Classes

.pull-left65[&lt;br&gt;

```
&lt;style&gt;
    p.error {color: red;   border: 1px solid red;} 
&lt;/style&gt;

    &lt;p class="error" align="left"&gt;Red highlight&lt;/p&gt;
```
]

.pull-right35[ 
&lt;br&gt;&lt;br&gt;&lt;br&gt;

&lt;style&gt;
p.error {
  color: red; border: 1px solid red;
} 
&lt;/style&gt;
&lt;p class="error"&gt;Red highlight&lt;/p&gt;

]

???
    
- don't worry if you don't understand everything
  - you should understand the logic: 
  - the stuff in the *greater than* and *less than* signs **TAGS** isn't printed but can tell us what role the text plays in the home page. 
  - the stuff also includes **attributes** that modify how it looks

---

&lt;br&gt;
## HTML tags: Practicalities


???

- In daily life, I use the CSS selectorgadget

--

.pull-right95[

&lt;img src = "./img/css-selector.jpg" width = 900 style="horizontal-align: middle"/&gt;

To easily access selectors, use Chrome [selector gadget](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb).]

???
- it's available in google chrome and allows you to click on an element; 
- all elements of the same attributes are then highlighted and can be deselected
- this way, you can use point &amp; click to select only the elements you want

---

&lt;br&gt;
## Practicing with the [CSS Diner](https://flukeout.github.io)
&lt;br&gt;

.pull-right85[&lt;img src="./img/css-diner.jpg" width=800/&gt;

]

???
- the **CSS Diner** allows practising, 
- [@Ivo] go to the page
- the first (of 32) level is solved like this; hovering over the elements let's you know how each is called; the moving ones should be selected
- the right column explains details to you
- Now @everyone, go to the page flukeout.github.io and practise for 5min

---

class: inverse, center, middle
## Let's start scraping in R

???

- I know this has been quite a bit of background; 
- but I hope that now you have a bit of an idea what and how we could collect data from the web
- so: let's start scraping 
- the good think in `R` is: no matter what you're trying to do - there's always a package for it
- so let's get started using a simple example and the package `rvest`
(- now use the rmarkdown file)

---

&lt;br&gt; 
## `rvest`

&lt;br&gt;&lt;br&gt;

.pull-left35[
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;img src="./img/rvest.png" width=300 style="vertical-align: middle"/&gt;
]

???

- `rvest` is an `R` package for scraping, 
- it's a wrapper around some other packages that is part of and integrates well with the tidyverse universe
- it is like the Swiss army knife of scraping: very versatile, widely applicable and rather intuitive to use

- it's strengths and weaknesses are also similar to that of the Swiss army knife:
    - [+] covers most frequent use cases and
    - [+] integrates with other packages, e.g. tidyverse very well; **but**
    - [-] it is also relatively simple: no dynamic webpages

- its main uses are 
  - getting tables, 
  - getting text, and
  - extracting links from home pages - and that's what we'll focus on today
  &lt;!--- (and downloading files) ---&gt;

--


.pull-right55[&lt;br&gt;&lt;br&gt;

### Main commands:
- `read_html()`
- `html_nodes()` / `html_node()`
- `html_text()`
- `html_table()`
- `html_attrs()` / `html_attr()`
]
???
The main functions of rvest are:
- `read_html()` - reads in an HTML page
- `html_nodes()` / `html_node()` - select nodes from an HTML document (i.e. extract pieces using selectors)
- `html_text()` - extracts the attributes, text, and the tag name from an html
- `html_table()` - parses an html table into a data frame
- `html_attrs()` / `html_attr()` - extracts attributes, text, and tag name from an html, e.g. the link text

---

&lt;br&gt;
## Scraping manually

&lt;br&gt;&lt;br&gt;

.pull-left25[

- Specify resource

&lt;br&gt;

- Read ("parse") resource

&lt;br&gt;

- select elements
]

.pull-right75[

```r
url_quotes &lt;- "http://quotes.toscrape.com" 
# call browseURL(url_quotes) to inspect page
```



```r
library(rvest)
page_quotes &lt;- url_quotes %&gt;% read_html()
```

&lt;br&gt;


```r
page_quotes %&gt;% html_text() # removes tags &amp; formatting

page_quotes %&gt;% html_nodes("a") # extract links 
    # &lt;a href="..."&gt;LINK TEXT 1&lt;/a&gt;
    # &lt;a href="..."&gt;LINK TEXT 2&lt;/a&gt;
```
]

???
scraping with R works in a specific way:
1. you manually specify a resource
2. then you instruct R to send a request to server that hosts website, and the server returns the requested resource
4. R parses the returned HTML (i.e., interprets the structure); BUT: R does not render the HTML in a nice fashion
5. you tell R which parts of the structure to focus on and what to extract

- how would we get only the TEXT of the links, not the links themselves (i.e. the &lt;a href="..."&gt;LINK TEXT&lt;/a&gt;)

---

class: inverse, center, middle 
## Let's practise
&lt;br&gt; &amp;rarr; Exercises in `worksheet.Rmd`

???
- ok, this is the end of the input
- We now practice with the worksheet. If you haven't done so, you can download it from the GitHub page
- I will put you into breakout rooms of 4-5 people; if you're stuck, ask around - and if you cannot figure it out together, and have searched for a solution online, use the "ask for help" function.
- If I'm not coming immediately, I'm with another group. then please be patient and try again some minutes later

- [if applicable] if we have more time, I will provide some extra information (about links and automation)

- please be back in the main room around 5:40, so we can quickly discuss remaining questions and then say goodbye; if you then want to stick around for virtual drinks, I have prepared a room.
---

class:inverse, middle, center
## Thank you

Click [here](https://www.wonder.me/r?id=195ebb26-39f5-410a-a67a-82c0e67ff532) to enter the wonder-room (password: "Alohomora!")

???
If we have more time, I will provide some more infos (and I have two extras)

But if this is not the case, this is the end.


---

&lt;br&gt;
## The process of scraping

&lt;img src="./diagrams/Folie11.png"&gt;


---

&lt;br&gt;
## The process of scraping

&lt;img src="./diagrams/Folie12.png"&gt;


---

&lt;br&gt;
## The process of scraping

&lt;img src="./diagrams/Folie13.png"&gt;

---

class: inverse, center, middle
## Extra (1): extracting links from webpages

---

&lt;br&gt;
## Links

.pull-left45[&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;img src="./img/links.jpg" height="480"&gt;]

???

- unlike a book that we read cover to cover,  webpages distribute information over multiple pages
- *hyperlinks* connect one page to the others &amp;rarr; we follow them by clicking
    - we need to deal with this differently when scraping
    
- We discussed links as a common case of attributes
    - content turned into a link with `&lt;a&gt;` tag (*anchor*)
    - link address specified as href attribute (*hyperreference*)
  
--

.pull-right45[
### Extracting links with rvest
&lt;br&gt;&lt;br&gt;
- link text:
    &lt;br&gt;&amp;nbsp; `html_nodes(page, "a") %&gt;%` &lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; `html_text()` &lt;br&gt;&lt;br&gt;
    
- hyperreference:
  &lt;br&gt;&amp;nbsp; `html_nodes(page, "a") %&gt;%` &lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; `html_attr("href")`

]

???

*Caution*: Link is attribute of `&lt;a&gt;`-Tag! So we will have to select the _link nodes_ (a) and then get the href _attributes_

`html_attr(page,"href")` vs. `html_nodes(page,"a") %&gt;% html_attr("href")`

---

class: inverse, center, middle
## Extra (2): scaling up

???

Just to give an outlook, we'll quickly discuss ways to scale up scraping

---

&lt;br&gt;
## Scaling up

???
- to scale up, we have two main ways of repeating code across different units

--

.pull-right75[

&lt;img src="./img/for-1.jpg" height="150"&gt;

&lt;br&gt;


&lt;img src="./img/sapply1.jpg" height="200"&gt;

]

???
- Our two options are (1) for-loops and (2) variants of the apply function
- we'll focus here on loops, 

Advantages
- their main advantage is that they're easy to write
- do not require full translation of code into functions
- easy to interrupt and continue for prolonged scraping

Disadvantages
- become inefficient for high numbers of iterations
- no swag: [stackoverflow: Are For loops evil in R?](https://stackoverflow.com/questions/30240573/are-for-loops-evil-in-r)

Good to know
- loops with `for` are just the most well-known type of loop
    - `while` loops
    - `repeat` loops
    - `break` and `next` clauses

---

&lt;br&gt;
## `for`- loops: application

.pull-left45[
&lt;br&gt;&lt;br&gt;&lt;br&gt;
### Example


```r
for (i in 1:length(urls)){
  text[i] &lt;- read_html(urls[i]) %&gt;% 
    html_nodes(".text") %&gt;% 
    html_text()
}
```

]

???
- We see here how we could employ a loop to extract a lot of text from some subpages in just a few lines of code
- imagine that `urls` is a vector of URLs that you scraped using the method to extract links that I showed before
- now you can easily just go through all subpages (to which you have the reference) and get any element from them that you want
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
